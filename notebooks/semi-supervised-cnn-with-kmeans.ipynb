{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dev-tf-kmean.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [{
      "cell_type": "markdown",
      "metadata": {
        "id": "OHgU6pxf62u0"
      },
      "source": [
        "A big thanks to <a href=\"https://github.com/ageron/handson-ml2/blob/master/09_unsupervised_learning.ipynb\">Aur√©lien Geron</a> and the team at Tensorflow for providing great [tutorials](https://www.tensorflow.org/tutorials). Most of the code below is adapted from their code for this use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/thekizoch/ml/blob/master/notebooks/semi-supervised-cnn-with-kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/thekizoch/ml/blob/master/notebooks/semi-supervised-cnn-with-kmeans.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKVZj1JR65Nq"
      },
      "source": [
        "# Semi-supervised CNN with K-means clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un2Xfg18Ug7O"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdm5EX_5R_Qn"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6p5JEJe75AL"
      },
      "source": [
        "## load mnist data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_YGBaLy7Wl8"
      },
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.target = mnist.target.astype(np.int64)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    mnist[\"data\"], mnist[\"target\"], random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4_0TJStCyfC"
      },
      "source": [
        "# scale data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcSl3h4GpmSn",
        "outputId": "0058bf70-32d7-4a10-d091-68d0703fc8ae"
      },
      "source": [
        "# shape of training data\n",
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [{
        "output_type": "execute_result",
        "data": {
          "text/plain": [
            "(52500, 784)"
          ]
        },
        "metadata": {},
        "execution_count": 4
      }]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TJyCdK8xU_5"
      },
      "source": [
        "## K-means clustering: manually labelled representative images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcXm-DIz8Bdv"
      },
      "source": [
        "We run a basic K-means clustering model from [scikit-learn](https://scikit-learn.org/stable/index.html) with 50 clusters on 52,500 training examples.\n",
        "\n",
        "Note this step takes over 5 minutes to run on Colab, due to our dataset size. This is much better than manually labelling over 50,000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3zNxIw_9APS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a936f4bc-2eb2-4170-820d-491961a40331"
      },
      "source": [
        "k = 50\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "X_digits_dist = kmeans.fit_transform(X_train)\n",
        "# show shape\n",
        "X_digits_dist.shape"
      ],
      "execution_count": 5,
      "outputs": [{
        "output_type": "execute_result",
        "data": {
          "text/plain": [
            "(52500, 50)"
          ]
        },
        "metadata": {},
        "execution_count": 5
      }]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwvwnh-4n3CA"
      },
      "source": [
        "Now we will choose the centroids of the 50 clusters as the representative images. These 50 images, in a real world application, we would label manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QT5jg-IVwWm"
      },
      "source": [
        "# get centroid images\n",
        "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
        "X_representative_digits = X_train[representative_digit_idx]\n",
        "# plot\n",
        "plt.figure(figsize=(8, 2))\n",
        "for index, X_representative_digit in enumerate(X_representative_digits):\n",
        "    plt.subplot(k // 10, 10, index + 1)\n",
        "    plt.imshow(X_representative_digit.reshape(28, 28), cmap=\"binary\", interpolation=\"bilinear\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmqCP-3F9oDB"
      },
      "source": [
        "In this case where the train data already contains the label, so we will just copy the labels over to save time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBbOVIF397U9"
      },
      "source": [
        "# confirm with image above\n",
        "y_representative_digits = y_train[representative_digit_idx]\n",
        "y_train[representative_digit_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6LyaJXWNCoX"
      },
      "source": [
        "## partial label propagation\n",
        "\n",
        "With these 50 representative labelled examples, we will label 50% of that training data that lies closest to each centroid. This is because examples that lie far from centroids are more likelly to be misclassified. \n",
        "\n",
        "If we did 100%, we would call this full label propagation.\n",
        "\n",
        "This percentile can be optimized, but that's out of scope for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQcuk2AJCKBY"
      },
      "source": [
        "percentile_closest = 50\n",
        "\n",
        "# define fully propagated y\n",
        "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
        "for i in range(k):\n",
        "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]\n",
        "\n",
        "# define partial label progation X and y\n",
        "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
        "for i in range(k):\n",
        "    in_cluster = (kmeans.labels_ == i)\n",
        "    cluster_dist = X_cluster_dist[in_cluster]\n",
        "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
        "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
        "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
        "\n",
        "partially_propagated = (X_cluster_dist != -1)\n",
        "\n",
        "X_train_partially_propagated = X_train[partially_propagated]\n",
        "y_train_partially_propagated = y_train_propagated[partially_propagated]\n",
        "\n",
        "X_train_partially_propagated.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pu1v0HJM30Y"
      },
      "source": [
        "## CNN on Mnist with semi-supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_jnPo9WSXWa"
      },
      "source": [
        "Before we use the 39,370 training examples with propagated labels, we need to get a baseline for how a CNN model would perform on only 50 random labeled examples.\n",
        "\n",
        "To speed development, we will use the Mnist dataset from Tensorflow and the [Keras Sequential API](https://www.tensorflow.org/guide/keras/overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB0iMJQHlZm4"
      },
      "source": [
        "## base line: CNN on only 50 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzKtoZMYlnrd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0VD2sunohul"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "# verify size\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJwoV2c5o2ol"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTU2PR80vRZj"
      },
      "source": [
        "# reshape\n",
        "train_images = train_images.reshape(train_images.shape + (1,))\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\n",
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl-ceQcxw5zX"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdx1G_EqTs9e"
      },
      "source": [
        "We build a simple CNN model architecture, which we will use for training on\n",
        "\n",
        "*   50 random labelled training images \n",
        "*   39,370 training images propagated from 50 labelled representative training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTt5wFFQo588"
      },
      "source": [
        "def get_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "  # add dnn\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLd3EDPQxVLL"
      },
      "source": [
        "## train and evaluate on 50 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtlkqtD0pcGP"
      },
      "source": [
        "# train\n",
        "train_num_examples = 50\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images[:train_num_examples], train_labels[:train_num_examples], epochs=10, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-p44W-YV33J"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(f'test accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quEyH9JsXDjM"
      },
      "source": [
        "We're not able to break 30% accuracy on examples the model has never seen before, using only 50 training examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zTsrN8MxxMa"
      },
      "source": [
        "## train and evaluate on propagated examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZGawwoG1S6c"
      },
      "source": [
        "We'll quickly verify that our data is in the same shape, and then train/evaluate. \n",
        "\n",
        "To save time, we'll only train for 5 epochs. Above we ran for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cibk3utm1dA8"
      },
      "source": [
        "X_train_partially_propagated = X_train_partially_propagated.reshape(\n",
        "    X_train_partially_propagated.shape[0],28,28)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train_partially_propagated[i])\n",
        "    # The CIFAR labels happen to be arrays, \n",
        "    # which is why you need the extra index\n",
        "    #plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hhvAPdc2Gw-"
      },
      "source": [
        "# reshape\n",
        "X_train_partially_propagated = X_train_partially_propagated.reshape(\n",
        "    X_train_partially_propagated.shape + (1,))\n",
        "X_train_partially_propagated.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2fCIe0MymJt"
      },
      "source": [
        "# train\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_partially_propagated, y_train_partially_propagated, epochs=5, \n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bP4ieA72V9Z"
      },
      "source": [
        "# evaluate\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(f'test accuracy: {test_acc}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY2oPA0gY-ph"
      },
      "source": [
        "## discussion, further investigation\n",
        "\n",
        "Using the partially propagated examples, were we able to boost test accuracy from 30% to 84%. \n",
        "\n",
        "This was done without any optimization on\n",
        "\n",
        "* k (number of clusters)\n",
        "* percentage of partial propagation\n",
        "* CNN Model architecture\n",
        "\n",
        "Most of the data in the world is unlabelled. Using the unsupervised learning algorithm of k-means clustering, we were able to boost accuracy considerably with a low requirement of labelled data."
      ]
    }
  ]
}
